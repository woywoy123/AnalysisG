/**
 * @brief Implementation for importing the base model template and its associated optimizer configuration.
 *
 * This function receives a tuple containing a pointer to a base `model_template` and
 * its corresponding `optimizer_params_t`. It first extracts these pointers.
 * The base model's `shush` flag is set to true to prevent verbose output during
 * the setup and testing phase. The base model's optimizer is set, although this
 * might be primarily for consistency as a clone is used for testing.
 *
 * Settings are cloned from the base model into a local `model_settings_t` variable.
 *
 * A temporary clone of the base model (`model_k`) is created to perform tests without
 * affecting the original base model. The optimizer configuration and the cloned settings
 * are applied to this temporary model instance. The `initialize` method is called on
 * the clone, likely setting up network layers and other necessary components based
 * on the configuration.
 *
 * To validate the setup, a set of random graph samples (`rnd`) is obtained from the
 * dataloader (`loader`). The function then iterates through these random samples,
 * calling `check_features` on the cloned model for each sample. This step verifies
 * that the model can process the data format correctly. The `shush` flag is re-enabled
 * for the model after the first check to minimize output during the loop.
 *
 * After the checks are complete, the temporary cloned model (`model_k`) is deleted
 * to free resources. A success message is logged.
 *
 * @param models A pointer to a std::tuple containing:
 *               - `model_template*`: Pointer to the base model template.
 *               - `optimizer_params_t*`: Pointer to the optimizer parameters for the model.
 * @note This function serves as a crucial pre-flight check, ensuring the model architecture,
 *       settings, and optimizer configuration are compatible with the data before starting
 *       the potentially time-consuming k-fold training process. The actual models used
 *       for each fold in `kfold_sessions` are assumed to be created and managed elsewhere,
 *       likely using `base->clone()` again.
 */

/**
 * @brief Implementation of the training loop for a single epoch and a specific k-fold split.
 *
 * This function executes one epoch of training for the model corresponding to the k-th fold.
 *
 * Steps:
 * 1. Retrieves the training dataset specific to fold `k` using `loader->get_k_train_set(k)`.
 * 2. Obtains a pointer to the `model_template` instance for fold `k` from `kfold_sessions`.
 * 3. Sets the model to training mode (`evaluation_mode(false)`), which typically enables features
 *    like dropout and batch normalization updates.
 * 4. Updates the model's internal epoch counter (`model->epoch`) to `epoch + 1`.
 * 5. Retrieves the `model_report` structure associated with this specific run (identified by
 *    run name and fold index `k`) from the `reports` map.
 * 6. Updates the report's current mode to "training" and records the current epoch number.
 * 7. Checks if batching is enabled (`m_settings.batch_size > 1`). If true, it calls
 *    `loader->build_batch` to group the samples into batches, potentially modifying the `smpl` pointer.
 * 8. Gets the total number of samples or batches (`l`) and updates the report (`mr->num_evnt`).
 * 9. Creates a `torch::AutoGradMode grd(true)` guard. This ensures that PyTorch/LibTorch tracks
 *    operations and computes gradients within this scope.
 * 10. Iterates through each sample or batch (`x` from 0 to `l-1`):
 *     a. Updates the report's iteration counter (`mr->iters`).
 *     b. Gets the current graph data (`gr`).
 *     c. Calls the model's `forward` method with the graph data and `training=true`. This performs
 *        the forward pass, calculates the loss, computes gradients, and likely triggers the
 *        optimizer step to update model parameters (assuming this logic is within `model->forward`
 *        or handled by attached hooks).
 *     d. Calls `metric->capture` to record performance metrics (e.g., loss, accuracy) for this
 *        training step, associating them with the current mode, fold, epoch, and total steps.
 * 11. After the loop finishes, calls `model->save_state()` to save the model's parameters and
 *     optimizer state, creating a checkpoint for this epoch.
 * 12. If batching was used, calls `loader->safe_delete(smpl)` to clean up the memory allocated
 *     for the batches.
 *
 * @param k The index of the current k-fold split (0 to k-1).
 * @param epoch The current epoch number (0 to `m_settings.epochs - 1`).
 * @note Gradient computation is enabled via `torch::AutoGradMode`.
 * @note Batching logic is handled conditionally based on settings.
 * @note Assumes the core training logic (loss calculation, backpropagation, optimizer step)
 *       is encapsulated within the `model->forward(..., true)` call or related model methods.
 */

/**
 * @brief Implementation of the validation loop for a single epoch and a specific k-fold split.
 *
 * This function executes one epoch of validation for the model corresponding to the k-th fold
 * using the validation dataset specific to that fold.
 *
 * Steps:
 * 1. Obtains a pointer to the `model_template` instance for fold `k` from `kfold_sessions`.
 * 2. Sets the model to evaluation mode (`evaluation_mode(true)`). This typically disables
 *    dropout and uses running statistics for batch normalization layers.
 * 3. Retrieves the `model_report` structure for the current run/fold.
 * 4. Updates the report's current mode to "validation".
 * 5. Retrieves the validation dataset specific to fold `k` using `loader->get_k_validation_set(k)`.
 * 6. Checks if batching is enabled (`m_settings.batch_size > 1`) and calls `loader->build_batch`
 *    if necessary.
 * 7. Creates a `torch::NoGradGuard no_grd` guard. This disables gradient calculation within its
 *    scope, which is essential for validation to prevent unnecessary computation and memory usage,
 *    and to ensure the model parameters are not updated.
 * 8. Gets the total number of validation samples or batches (`l`) and updates the report (`mr->num_evnt`).
 * 9. Iterates through each sample or batch (`x` from 0 to `l-1`):
 *     a. Updates the report's iteration counter (`mr->iters`).
 *     b. Gets the current graph data (`gr`).
 *     c. Calls the model's `forward` method with the graph data and `training=false`. This performs
 *        only the forward pass to get predictions or embeddings. Loss calculation might be skipped
 *        or handled differently compared to training.
 *     d. Calls `metric->capture` to record validation performance metrics (e.g., validation loss,
 *        accuracy), associating them with the current mode (validation), fold, epoch, and total steps.
 * 10. (Potential) If batching was used, cleanup of the batched data (`smpl`) might be required,
 *     similar to the `training_loop`. (Note: `safe_delete` call is commented out in the original code).
 *
 * @param k The index of the current k-fold split (0 to k-1).
 * @param epoch The current epoch number (0 to `m_settings.epochs - 1`).
 * @note Gradient computation is explicitly disabled using `torch::NoGradGuard`.
 * @note The model is set to evaluation mode.
 * @note Batching logic is handled conditionally.
 */

/**
 * @brief Implementation of the evaluation loop on the test set using the model from a specific fold.
 *
 * This function evaluates the performance of the model trained for fold `k` (up to the current `epoch`)
 * on the common, unseen test dataset.
 *
 * Steps:
 * 1. Obtains a pointer to the `model_template` instance for fold `k` from `kfold_sessions`.
 * 2. Sets the model to evaluation mode (`evaluation_mode(true)`).
 * 3. Retrieves the `model_report` structure for the current run/fold.
 * 4. Updates the report's current mode to "evaluation".
 * 5. Retrieves the common test dataset using `loader->get_test_set()`. This dataset is typically
 *    the same regardless of the fold `k`.
 * 6. Checks if batching is enabled (`m_settings.batch_size > 1`) and calls `loader->build_batch`
 *    if necessary.
 * 7. Creates a `torch::NoGradGuard no_grd` guard to disable gradient calculations during evaluation.
 * 8. Gets the total number of test samples or batches (`l`) and updates the report (`mr->num_evnt`).
 * 9. Iterates through each sample or batch (`x` from 0 to `l-1`):
 *     a. Updates the report's iteration counter (`mr->iters`).
 *     b. Gets the current graph data (`gr`).
 *     c. Calls the model's `forward` method with the graph data and `training=false` to perform
 *        the forward pass and obtain predictions.
 *     d. Calls `metric->capture` to record evaluation performance metrics (e.g., test loss,
 *        accuracy, F1-score) on the test set, associating them with the current mode (evaluation),
 *        fold, epoch, and total steps.
 * 10. (Potential) If batching was used, cleanup of the batched data (`smpl`) might be required.
 *     (Note: `safe_delete` call is commented out in the original code).
 *
 * @param k The index of the k-fold split whose model is being evaluated (0 to k-1).
 * @param epoch The current epoch number (0 to `m_settings.epochs - 1`). The model state used
 *              for evaluation corresponds to the state after training epoch `epoch`.
 * @note Gradient computation is explicitly disabled using `torch::NoGradGuard`.
 * @note The model is set to evaluation mode.
 * @note Uses the shared test set provided by the dataloader.
 * @note Batching logic is handled conditionally.
 */

/**
 * @brief Implementation for launching the complete training, validation, and evaluation process
 *        for a specific k-fold model over all epochs.
 *
 * This function orchestrates the entire lifecycle for the model associated with fold `k`.
 *
 * Steps:
 * 1. Enters a loop that iterates from epoch 0 up to (but not including) `m_settings.epochs`.
 * 2. Inside the loop, retrieves the `model_template` instance for fold `k`.
 * 3. Checks if the model's internal epoch counter (`model->epoch`) is greater than the current
 *    loop epoch (`ep`). If true, it means this epoch has already been completed (e.g., resuming
 *    from a checkpoint), so the loop continues to the next epoch (`continue`).
 * 4. Conditionally calls the respective loop functions based on flags in `m_settings`:
 *    - If `m_settings.training` is true, calls `training_loop(k, ep)`.
 *    - If `m_settings.validation` is true, calls `validation_loop(k, ep)`.
 *    - If `m_settings.evaluation` is true, calls `evaluation_loop(k, ep)`.
 * 5. Retrieves the `model_report` for the current run/fold.
 * 6. Sets `mr->waiting_plot = this->metric`. This likely signals to an external monitoring
 *    system or the main thread that plotting operations related to the metrics collected
 *    in this epoch might be pending. The `metrics` object itself is responsible for
 *    clearing this pointer (setting it back to `nullptr`) once plotting is complete.
 * 7. Checks if `m_settings.debug_mode` is true:
 *    - If true, it immediately calls `this->metric->dump_plots(k)` to generate and save plots
 *      synchronously for debugging purposes.
 *    - It then skips the waiting logic (`continue`) and proceeds to the next epoch.
 * 8. If not in debug mode, enters a `while` loop that checks if `mr->waiting_plot` is still
 *    pointing to the `metric` object (i.e., not `nullptr`).
 *    - While waiting, it pauses the current thread for a very short duration
 *      (`std::chrono::microseconds(10)`) using `std::this_thread::sleep_for`. This prevents
 *      a busy-wait loop, yielding CPU time while waiting for the asynchronous plotting
 *      (presumably handled by the `metrics` object) to finish.
 * 9. After the epoch loop completes (all epochs are processed), retrieves the `model_report` again.
 * 10. Sets `mr->is_complete = true` to mark this fold's run as finished.
 *
 * @param k The index of the k-fold split to launch (0 to k-1).
 * @note This function acts as the main driver for a single fold's training/validation/evaluation process.
 * @note It supports resuming training by checking `model->epoch`.
 * @note It handles conditional execution of training, validation, and evaluation phases.
 * @note It includes logic to wait for potentially asynchronous plotting operations managed by the
 *       `metrics` object, unless running in debug mode.
 */
 * @file optimizer.h
 * @brief Defines the optimizer class responsible for managing the training, validation,
 *        and evaluation loops for machine learning models using k-fold cross-validation.
 */

#ifndef OPTIMIZER_GENERATOR_H
#define OPTIMIZER_GENERATOR_H

#include <templates/model_template.h>
#include <generators/dataloader.h>
#include <metrics/metrics.h>
#include <structs/settings.h>
#include <tools.h>        // Assuming tools provides common utilities
#include <notification.h> // Assuming notification provides logging/messaging capabilities
#include <map>
#include <string>
#include <vector>
#include <tuple>
#include <thread>         // For std::this_thread
#include <chrono>         // For std::chrono

// Forward declaration
class analysis;

/**
 * @class optimizer
 * @brief Manages the overall training, validation, and evaluation process for models.
 *
 * This class orchestrates the machine learning workflow. It handles k-fold cross-validation,
 * manages model instances for each fold, interacts with the dataloader to get data subsets,
 * runs the training, validation, and evaluation loops, and collects metrics.
 * It inherits from `tools` and `notification` likely for utility functions and logging/messaging.
 */
class optimizer : public tools, public notification {
public:
    /**
     * @brief Constructor for the optimizer class.
     * Initializes the optimizer, sets the logging prefix, and creates a metrics object.
     */
    optimizer();

    /**
     * @brief Destructor for the optimizer class.
     * Cleans up resources, specifically deleting the metrics object and all model instances
     * stored in the kfold_sessions map.
     */
    ~optimizer();

    /**
     * @brief General settings for the optimization process.
     * Holds configuration parameters like number of epochs, batch size, run name, etc.
     */
    settings_t m_settings;

    /**
     * @brief Imports the dataloader instance to be used by the optimizer.
     * @param dl A pointer to the dataloader object responsible for providing data.
     * @note Also configures the internal metrics object with the optimizer's settings.
     */
    void import_dataloader(dataloader* dl);

    /**
     * @brief Imports the base model template and its associated optimizer parameters.
     *
     * This function takes a tuple containing a base model template and its optimizer configuration.
     * It clones the base model, configures it with the provided parameters, and performs
     * initial checks and tests using random data samples from the dataloader to ensure
     * compatibility and correct setup before starting the main training process.
     *
     * @param models A pointer to a tuple containing:
     *               - `model_template*`: A pointer to the base model template to be cloned for each fold.
     *               - `optimizer_params_t*`: A pointer to the optimizer configuration specific to the model.
     * @note The base model's `shush` flag is set to true to suppress output during cloning/testing.
     * @note A temporary clone of the model is created and tested within this function.
     */
    void import_model_sessions(std::tuple<model_template*, optimizer_params_t*>* models);

    /**
     * @brief Executes a single training epoch for a specific k-fold split.
     *
     * Retrieves the training dataset for fold 'k', sets the model to training mode,
     * iterates through the training samples (potentially batched), performs forward passes,
     * computes gradients (implicitly via AutoGradMode), updates model parameters (handled within model->forward),
     * captures metrics, and saves the model state after the epoch.
     *
     * @param k The index of the current k-fold split (0 to k-1).
     * @param epoch The current epoch number (0 to epochs-1).
     * @note Enables gradient calculation using `torch::AutoGradMode`.
     * @note Handles batching if `m_settings.batch_size > 1`.
     * @note Updates the corresponding `model_report` with training progress.
     */
    void training_loop(int k, int epoch);

    /**
     * @brief Executes a single validation epoch for a specific k-fold split.
     *
     * Retrieves the validation dataset for fold 'k', sets the model to evaluation mode,
     * iterates through the validation samples (potentially batched), performs forward passes
     * without gradient calculation, and captures validation metrics.
     *
     * @param k The index of the current k-fold split (0 to k-1).
     * @param epoch The current epoch number (0 to epochs-1).
     * @note Disables gradient calculation using `torch::NoGradGuard`.
     * @note Handles batching if `m_settings.batch_size > 1`.
     * @note Updates the corresponding `model_report` with validation progress.
     */
    void validation_loop(int k, int epoch);

    /**
     * @brief Executes a single evaluation epoch on the test set for a specific k-fold split's model.
     *
     * Retrieves the test dataset, sets the model (trained up to the current epoch for fold 'k')
     * to evaluation mode, iterates through the test samples (potentially batched), performs
     * forward passes without gradient calculation, and captures evaluation metrics.
     *
     * @param k The index of the k-fold split whose model is being evaluated (0 to k-1).
     * @param epoch The current epoch number (used for reporting purposes, model state corresponds to this epoch).
     * @note Disables gradient calculation using `torch::NoGradGuard`.
     * @note Handles batching if `m_settings.batch_size > 1`.
     * @note Updates the corresponding `model_report` with evaluation progress.
     * @note Uses the common test set provided by the dataloader.
     */
    void evaluation_loop(int k, int epoch);

    /**
     * @brief Launches the complete training, validation, and evaluation process for a specific k-fold model.
     *
     * Iterates through the specified number of epochs (`m_settings.epochs`). In each epoch,
     * it conditionally calls `training_loop`, `validation_loop`, and `evaluation_loop` based
     * on the flags in `m_settings`. It handles potential skipping of already completed epochs
     * and waits for asynchronous plotting operations (if any) managed by the `metrics` object
     * to complete before proceeding to the next epoch.
     *
     * @param k The index of the k-fold split to launch (0 to k-1).
     * @note Checks `model->epoch` to potentially resume training.
     * @note Dumps plots via `metric->dump_plots(k)` if `m_settings.debug_mode` is true.
     * @note Waits for `mr->waiting_plot` (pointer to the metrics object) to become null,
     *       indicating plotting is finished for the epoch, unless in debug mode.
     * @note Marks the `model_report` as complete (`is_complete = true`) after all epochs finish.
     */
    void launch_model(int k);

    /**
     * @brief Map storing the model instance for each k-fold split.
     * The key is the fold index (int k), and the value is a pointer to the `model_template` instance.
     */
    std::map<int, model_template*> kfold_sessions = {};

    /**
     * @brief Map storing reports for each model run (potentially per fold).
     * The key is a string identifier (e.g., run_name + fold_index), and the value is a pointer
     * to a `model_report` struct containing run status and results.
     */
    std::map<std::string, model_report*> reports = {};

    /**
     * @brief Pointer to the metrics collector object.
     * Used to record performance metrics during training, validation, and evaluation.
     */
    metrics* metric = nullptr;

    /**
     * @brief Pointer to the dataloader object.
     * Used to fetch training, validation, and test data subsets.
     */
    dataloader* loader = nullptr;
};

#endif // OPTIMIZER_GENERATOR_H

// --- Implementation ---
// Note: Doxygen comments for implementation details are usually less common
// unless explaining complex logic within a function. The header provides the interface documentation.

// #include <generators/optimizer.h> // This include seems misplaced here, usually implementation goes in a .cpp file

/**
 * @fn optimizer::optimizer()
 * @brief Implementation of the optimizer constructor.
 */
optimizer::optimizer() {
    this->prefix = "optimizer"; // Set logging prefix
    this->metric = new metrics(); // Allocate metrics object
}

/**
 * @fn optimizer::~optimizer()
 * @brief Implementation of the optimizer destructor.
 */
optimizer::~optimizer() {
    delete this->metric; // Deallocate metrics object
    this->metric = nullptr;
    // Iterate through kfold_sessions and delete each model instance
    std::map<int, model_template*>::iterator itx = this->kfold_sessions.begin();
    for (; itx != this->kfold_sessions.end(); ++itx) {
        delete itx->second;
        itx->second = nullptr; // Good practice to nullify pointer after deletion
    }
    this->kfold_sessions.clear(); // Clear the map
    // Note: Assuming model_report objects in 'reports' are managed elsewhere or don't need deletion here.
    // If they need deletion, similar cleanup logic would be required.
}

/**
 * @fn void optimizer::import_dataloader(dataloader* dl)
 * @brief Implementation for importing the dataloader.
 */
void optimizer::import_dataloader(dataloader* dl) {
    this->metric->m_settings = this->m_settings; // Pass settings to metrics object
    this->loader = dl;                           // Store pointer to dataloader
}

/**
 * @fn void optimizer::import_model_sessions(std::tuple<model_template*, optimizer_params_t*>* models)
 * @brief Implementation for importing the base model and configuration.
 */
void optimizer::import_model_sessions(std::tuple<model_template*, optimizer_params_t*>* models) {
    // Extract base model and config from the tuple
    model_template* base = std::get<0>(*models);
    optimizer_params_t* config = std::get<1>(*models);

    base->shush = true; // Suppress output from base model during setup
    base->set_optimizer(config->optimizer); // Configure base model optimizer (might be redundant if cloned below)

    model_settings_t settings;
    base->clone_settings(&settings); // Get settings from the base model

    this->info("_____ TESTING IMPORTED MODEL WITH OPTIMIZER PARAMS _____");
    // Create a temporary clone for testing
    model_template* model_k = base->clone();
    model_k->set_optimizer(config->optimizer); // Apply optimizer config to the clone
    model_k->import_settings(&settings);       // Apply settings to the clone
    model_k->initialize(config);               // Initialize the clone (e.g., build network layers)

    // Test the cloned model with random data samples
    std::vector<graph_t*> rnd = this->loader->get_random(this->m_settings.num_examples);
    for (size_t x(0); x < rnd.size(); ++x) {
        if (x) { model_k->shush = true; } // Suppress output after the first check
        model_k->check_features(rnd[x]); // Perform feature check (example usage)
    }
    delete model_k; // Clean up the temporary test model
    this->success("_____ PASSED TESTS AND CONFIGURATION _____");
    // Note: The actual models for k-folds are likely created elsewhere, possibly using the base model.
}

/**
 * @fn void optimizer::training_loop(int k, int epoch)
 * @brief Implementation of the training loop for one epoch and fold.
 */
void optimizer::training_loop(int k, int epoch) {
    // Get training data for the fold
    std::vector<graph_t*>* smpl = this->loader->get_k_train_set(k);
    model_template* model = this->kfold_sessions[k]; // Get model for the fold
    model->evaluation_mode(false); // Set model to training mode (e.g., enable dropout)
    model->epoch = epoch + 1;      // Update model's internal epoch counter

    // Get the report object for this fold/run
    model_report* mr = this->reports[this->m_settings.run_name + std::to_string(k)];
    mr->mode = "training"; // Update report status
    mr->epoch = epoch;

    // Handle batching if enabled
    bool batched = this->m_settings.batch_size > 1;
    if (batched) { smpl = this->loader->build_batch(smpl, model, mr); } // Let dataloader create batches
    size_t l = smpl->size(); // Number of samples/batches
    mr->num_evnt = l;

    torch::AutoGradMode grd(true); // Enable gradient computation in this scope
    for (size_t x(0); x < l; ++x) {
        mr->iters = x; // Update report iteration count
        graph_t* gr = (*smpl)[x]; // Get current sample/batch
        // Perform forward pass, calculate loss, and update weights (details inside model->forward)
        model->forward(gr, true); // true indicates training mode (e.g., calculate loss)
        // Capture metrics (loss, accuracy, etc.)
        this->metric->capture(mode_enum::training, k, epoch, l);
    }
    model->save_state(); // Save model checkpoint after epoch
    // Clean up batched data if it was created
    if (!batched) { return; }
    this->loader->safe_delete(smpl); // Assuming dataloader manages deletion of batches
}

/**
 * @fn void optimizer::validation_loop(int k, int epoch)
 * @brief Implementation of the validation loop for one epoch and fold.
 */
void optimizer::validation_loop(int k, int epoch) {
    model_template* model = this->kfold_sessions[k]; // Get model for the fold
    model->evaluation_mode(true); // Set model to evaluation mode (e.g., disable dropout)

    // Get the report object
    model_report* mr = this->reports[this->m_settings.run_name + std::to_string(k)];
    mr->mode = "validation"; // Update report status

    // Get validation data
    std::vector<graph_t*>* smpl = this->loader->get_k_validation_set(k);
    // Handle batching
    bool batched = this->m_settings.batch_size > 1;
    if (batched) { smpl = this->loader->build_batch(smpl, model, mr); }

    torch::NoGradGuard no_grd; // Disable gradient computation in this scope
    size_t l = smpl->size();   // Number of samples/batches
    mr->num_evnt = l;
    for (size_t x(0); x < l; ++x) {
        mr->iters = x; // Update report iteration count
        graph_t* gr = (*smpl)[x]; // Get current sample/batch
        // Perform forward pass without calculating loss/gradients for validation
        model->forward(gr, false); // false indicates evaluation mode
        // Capture validation metrics
        this->metric->capture(mode_enum::validation, k, epoch, l);
    }
    // Clean up batched data if created (assuming similar logic to training_loop)
    // if (batched) { this->loader->safe_delete(smpl); } // Add if necessary
}

/**
 * @fn void optimizer::evaluation_loop(int k, int epoch)
 * @brief Implementation of the evaluation loop on the test set.
 */
void optimizer::evaluation_loop(int k, int epoch) {
    model_template* model = this->kfold_sessions[k]; // Get model for the fold
    model->evaluation_mode(true); // Set model to evaluation mode

    // Get the report object
    model_report* mr = this->reports[this->m_settings.run_name + std::to_string(k)];
    mr->mode = "evaluation"; // Update report status

    // Get test data (common for all folds)
    std::vector<graph_t*>* smpl = this->loader->get_test_set();
    // Handle batching
    bool batched = this->m_settings.batch_size > 1;
    if (batched) { smpl = this->loader->build_batch(smpl, model, mr); }

    torch::NoGradGuard no_grd; // Disable gradient computation
    size_t l = smpl->size();   // Number of samples/batches
    mr->num_evnt = l;
    for (size_t x(0); x < l; ++x) {
        mr->iters = x; // Update report iteration count
        graph_t* gr = (*smpl)[x]; // Get current sample/batch
        // Perform forward pass for evaluation
        model->forward(gr, false); // false indicates evaluation mode
        // Capture evaluation metrics
        this->metric->capture(mode_enum::evaluation, k, epoch, l);
    }
    // Clean up batched data if created (assuming similar logic to training_loop)
    // if (batched) { this->loader->safe_delete(smpl); } // Add if necessary
}

/**
 * @fn void optimizer::launch_model(int k)
 * @brief Implementation for launching the full process for one fold.
 */
void optimizer::launch_model(int k) {
    for (int ep(0); ep < this->m_settings.epochs; ++ep) {
        model_template* model = this->kfold_sessions[k];
        // Resume check: Skip epochs already completed by this model instance
        if (model->epoch > ep) { continue; }

        // Conditionally run loops based on settings
        if (this->m_settings.training) { this->training_loop(k, ep); }
        if (this->m_settings.validation) { this->validation_loop(k, ep); }
        if (this->m_settings.evaluation) { this->evaluation_loop(k, ep); }

        // Handle plotting/reporting
        model_report* mr = this->reports[this->m_settings.run_name + std::to_string(k)];
        mr->waiting_plot = this->metric; // Signal that plots might be generated

        if (this->m_settings.debug_mode) {
            this->metric->dump_plots(k); // Dump plots immediately in debug mode
            mr->waiting_plot = nullptr; // Assume plotting is synchronous/not waited for in debug
            continue; // Proceed to next epoch
        }

        // Wait for potential asynchronous plotting to finish
        // The metrics object likely sets mr->waiting_plot to nullptr when done.
        while (mr->waiting_plot) {
            std::this_thread::sleep_for(std::chrono::microseconds(10)); // Small sleep to avoid busy-waiting
        }
    }

    // Mark the report as complete after all epochs
    model_report* mr = this->reports[this->m_settings.run_name + std::to_string(k)];
    mr->is_complete = true;
}
    model_template*       base = std::get<0>(*models); 
    optimizer_params_t* config = std::get<1>(*models); 

    base -> shush = true; 
    base -> set_optimizer(config -> optimizer); 
    
    model_settings_t settings;
    base -> clone_settings(&settings); 

    this -> info("_____ TESTING IMPORTED MODEL WITH OPTIMIZER PARAMS _____"); 
    model_template* model_k = base -> clone(); 
    model_k -> set_optimizer(config -> optimizer); 
    model_k -> import_settings(&settings); 
    model_k -> initialize(config); 
    std::vector<graph_t*> rnd = this -> loader -> get_random(this -> m_settings.num_examples); 
    for (size_t x(0); x < rnd.size(); ++x){
        if (x){model_k -> shush = true;} 
        model_k -> check_features(rnd[x]);
    }
    delete model_k; 
    this -> success("_____ PASSED TESTS AND CONFIGURATION _____"); 
}

void optimizer::training_loop(int k, int epoch){
    std::vector<graph_t*>* smpl = this -> loader -> get_k_train_set(k); 
    model_template* model = this -> kfold_sessions[k]; 
    model -> evaluation_mode(false);
    model -> epoch = epoch+1; 

    model_report* mr = this -> reports[this -> m_settings.run_name + std::to_string(k)]; 
    mr -> mode = "training";
    mr -> epoch = epoch;  

    bool batched = this -> m_settings.batch_size > 1;
    if (batched){smpl = this -> loader -> build_batch(smpl, model, mr);}
    size_t l = smpl -> size(); 
    mr -> num_evnt = l;

    torch::AutoGradMode grd(true); 
    for (size_t x(0); x < l; ++x){
        mr -> iters = x; 
        graph_t* gr = (*smpl)[x]; 
        model -> forward(gr, true);
        this -> metric -> capture(mode_enum::training, k, epoch, l); 
    }
    model -> save_state(); 
    if (!batched){return;}
    this -> loader -> safe_delete(smpl);
}

void optimizer::validation_loop(int k, int epoch){
    model_template* model = this -> kfold_sessions[k]; 
    model -> evaluation_mode(true); 

    model_report* mr = this -> reports[this -> m_settings.run_name + std::to_string(k)]; 
    mr -> mode = "validation"; 

    std::vector<graph_t*>* smpl = this -> loader -> get_k_validation_set(k); 
    bool batched = this -> m_settings.batch_size > 1;
    if (batched){smpl = this -> loader -> build_batch(smpl, model, mr);}

    torch::NoGradGuard no_grd;  
    size_t l = smpl -> size(); 
    mr -> num_evnt = l; 
    for (size_t x(0); x < l; ++x){
        mr -> iters = x; 
        graph_t* gr = (*smpl)[x]; 
        model -> forward(gr, false);
        this -> metric -> capture(mode_enum::validation, k, epoch, l); 
    }
}

void optimizer::evaluation_loop(int k, int epoch){
    model_template* model = this -> kfold_sessions[k]; 
    model -> evaluation_mode(true); 
    model_report* mr = this -> reports[this -> m_settings.run_name + std::to_string(k)]; 
    mr -> mode = "evaluation"; 

    std::vector<graph_t*>* smpl = this -> loader -> get_test_set(); 
    bool batched = this -> m_settings.batch_size > 1;
    if (batched){smpl = this -> loader -> build_batch(smpl, model, mr);}

    torch::NoGradGuard no_grd;  
    size_t l = smpl -> size(); 
    mr -> num_evnt = l; 
    for (size_t x(0); x < l; ++x){
        mr -> iters = x; 
        graph_t* gr = (*smpl)[x]; 
        model -> forward(gr, false);
        this -> metric -> capture(mode_enum::evaluation, k, epoch, l); 
    }
}

void optimizer::launch_model(int k){
    for (int ep(0); ep < this -> m_settings.epochs; ++ep){
        model_template* model = this -> kfold_sessions[k]; 
        if (model -> epoch > ep){continue;}
        if (this -> m_settings.training){this -> training_loop(k, ep);}
        if (this -> m_settings.validation){this -> validation_loop(k, ep);}
        if (this -> m_settings.evaluation){this -> evaluation_loop(k, ep);}
        if (this -> m_settings.debug_mode){this -> metric -> dump_plots(k);}

        model_report* mr = this -> reports[this -> m_settings.run_name + std::to_string(k)]; 
        mr -> waiting_plot = this -> metric; 
        if (this -> m_settings.debug_mode){this -> metric -> dump_plots(k); continue;}
        while (mr -> waiting_plot){std::this_thread::sleep_for(std::chrono::microseconds(10));}
    }

    model_report* mr = this -> reports[this -> m_settings.run_name + std::to_string(k)]; 
    mr -> is_complete = true; 
}


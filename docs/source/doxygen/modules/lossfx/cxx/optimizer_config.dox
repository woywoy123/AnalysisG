/**
 * @file optimizer_config.cxx
 * @brief COMPLETE documentation for optimizer_config.cxx
 *
 * @details
 * Location: modules/lossfx/cxx/optimizer_config.cxx
 * Type: .cxx source file
 * Lines: 174
 * Size: 8001 bytes
 *
 * ## Includes
 * - `#include <templates/lossfx.h>`
 *
 * ## Function Implementations
 * - `h>

void lossfx::build_adam(optimizer_params_t* op, std::vector<torch::Tensor>* params)`
 * - ` if(this -> m_adam)`
 * - ` if(op -> m_betas)`
 * - ` if(op -> m_eps)`
 * - ` if(op -> m_weight_decay)`
 * - ` if(op -> m_amsgrad)`
 * - ` if(op -> m_betas)`
 * - ` if(op -> m_eps)`
 * - ` if(op -> m_weight_decay)`
 * - ` if(op -> m_amsgrad)`
 * - `void lossfx::build_adagrad(optimizer_params_t* op, std::vector<torch::Tensor>* params)`
 * - ` if(this -> m_adagrad)`
 * - ` if(op -> m_lr_decay)`
 * - ` if(op -> m_weight_decay)`
 * - ` if(op -> m_initial_accumulator_value)`
 * - ` if(op -> m_eps)`
 * - ` if(op -> m_lr_decay)`
 * - ` if(op -> m_weight_decay)`
 * - ` if(op -> m_initial_accumulator_value)`
 * - ` if(op -> m_eps)`
 * - `void lossfx::build_adamw(optimizer_params_t* op, std::vector<torch::Tensor>* params)`
 * - ` if(this -> m_adamw)`
 * - ` if(op -> m_betas)`
 * - ` if(op -> m_eps)`
 * - ` if(op -> m_weight_decay)`
 * - ` if(op -> m_amsgrad)`
 * - ` if(op -> m_betas)`
 * - ` if(op -> m_eps)`
 * - ` if(op -> m_weight_decay)`
 * - ` if(op -> m_amsgrad)`
 * - `void lossfx::build_lbfgs(optimizer_params_t* op, std::vector<torch::Tensor>* params)`
 * - ` if(this -> m_lbfgs)`
 * - ` if(op -> m_max_iter)`
 * - ` if(op -> m_tolerance_grad)`
 * - ` if(op -> m_tolerance_change)`
 * - ` if(op -> m_max_iter)`
 * - ` if(op -> m_max_eval)`
 * - ` if(op -> m_history_size)`
 * - `void lossfx::build_rmsprop(optimizer_params_t* op, std::vector<torch::Tensor>* params)`
 * - ` if(this -> m_rmsprop)`
 * - ` if(op -> m_alpha)`
 * - ` if(op -> m_eps)`
 * - ` if(op -> m_weight_decay)`
 * - ` if(op -> m_momentum)`
 * - ` if(op -> m_centered)`
 * - `void lossfx::build_sgd(optimizer_params_t* op, std::vector<torch::Tensor>* params)`
 * - ` if(this -> m_sgd)`
 * - ` if(op -> m_momentum)`
 * - ` if(op -> m_dampening)`
 * - ` if(op -> m_weight_decay)`
 * - ` if(op -> m_nesterov)`
 * - ` if(op -> m_momentum)`
 * - ` if(op -> m_dampening)`
 * - ` if(op -> m_weight_decay)`
 * - ` if(op -> m_nesterov)`
 * - `static void m_xavier_normal(torch::nn::Module& m)`
 * - `static void m_xavier_uniform(torch::nn::Module& m)`
 * - `static void m_normal(torch::nn::Module& m)`
 * - `static void m_uniform(torch::nn::Module& m)`
 * - `static void m_kaiming_normal(torch::nn::Module& m)`
 * - `static void m_kaiming_uniform(torch::nn::Module& m)`
 * - `void lossfx::weight_init(torch::nn::Sequential* data, mlp_init method)`
 * - ` switch(method)`
 *
 * @note This file has been COMPLETELY documented.
 * @note Every class, struct, function, variable, macro is listed above.
 * @see Doxygen HTML output for full cross-references
 */
# Quick Start Tutorial

This tutorial will guide you through setting up a basic analysis using the AnalysisG framework.

## Prerequisites

Before starting, ensure you have:
- Installed AnalysisG following the [installation guide](../installation.md)
- Downloaded some sample data files (or use the example data provided with the framework)

## 1. Create a Simple Analysis Script

Create a file named `simple_analysis.cpp`:

```cpp
/**
 * @file simple_analysis.cpp
 * @brief A basic example demonstrating data processing with AnalysisG.
 *
 * This script sets up a minimal analysis pipeline to process input data,
 * build graph representations, and save the output.
 */

// Include the core AnalysisG framework header.
#include <AnalysisG/analysis.h>
// Include the specific event definition for ssml_mc20 data.
#include <ssml_mc20/event.h>
// Include the specific graph building logic for jets.
#include <ssml_mc20/graphs.h>

/**
 * @brief Main entry point for the simple analysis script.
 * @return int Returns 0 upon successful execution, non-zero otherwise.
 */
int main() {
    /**
     * @brief Create a new analysis object.
     * This object orchestrates the entire analysis workflow.
     */
    // analysis* an = new analysis();

    /**
     * @brief Configure the output path for generated files.
     * All results will be stored in the './output' directory.
     */
    // an->settings.output_path = "./output";

    /**
     * @brief Assign a name to this specific analysis run.
     * This helps in organizing outputs, especially when running multiple analyses.
     */
    // an->settings.run_name = "quickstart";

    /**
     * @brief Add input data samples to the analysis.
     * @param path Path to the directory containing sample files.
     * @param name A label or tag for this dataset (e.g., "ttbar").
     * The framework will scan the specified directory for compatible data files.
     */
    // an->add_samples("./sample_data/", "ttbar");

    /**
     * @brief Instantiate the event processing logic for ssml_mc20 data.
     * This object knows how to interpret the raw input data format.
     */
    // ssml_mc20* event = new ssml_mc20();

    /**
     * @brief Register the event processing template with the analysis.
     * @param event Pointer to the event processing object.
     * @param name A unique identifier for this event template ("mc20").
     * This tells the analysis how to handle events of type "mc20".
     */
    // an->add_event_template(event, "mc20");

    /**
     * @brief Instantiate the graph building logic for jets.
     * This object defines how to construct graphs from the processed event data.
     */
    // graph_jets* graph = new graph_jets();

    /**
     * @brief Register the graph building template with the analysis.
     * @param graph Pointer to the graph building object.
     * @param name A unique identifier for this graph template ("jets").
     * This tells the analysis how to build graphs named "jets".
     */
    // an->add_graph_template(graph, "jets");

    /**
     * @brief Execute the analysis pipeline.
     * This triggers data loading, event processing, graph building, and output saving
     * based on the configurations provided above.
     */
    // an->build();

    /**
     * @brief Clean up allocated resources.
     * It's important to delete the dynamically allocated analysis object
     * to prevent memory leaks.
     */
    // delete an;

    /**
     * @brief Indicate successful program termination.
     */
    // return 0;
}
```

## 2. Compile and Run Your Analysis

```bash
# Compile the C++ script using CMake
mkdir build && cd build
cmake ..
make

# Execute the compiled analysis program
./simple_analysis
```

This will process the data, creating graph representations that are saved to the output directory.

## 3. Add a Machine Learning Model

Now let's extend our analysis to include a simple GNN model:

```cpp
/**
 * @file analysis_with_ml.cpp
 * @brief Example demonstrating AnalysisG with a simple GNN model for training.
 *
 * This script extends the basic analysis by adding a Graph Neural Network (GNN)
 * model, configuring training parameters, and running the training process.
 */

// Include the core AnalysisG framework header.
#include <AnalysisG/analysis.h>
// Include the specific event definition for ssml_mc20 data.
#include <ssml_mc20/event.h>
// Include the specific graph building logic for jets.
#include <ssml_mc20/graphs.h>

/**
 * @class SimpleGNN
 * @brief A basic Graph Neural Network model implementation inheriting from model_template.
 *
 * This class defines a simple GNN architecture with a node encoder and an edge classifier,
 * suitable for demonstration purposes within the AnalysisG framework. It utilizes LibTorch
 * for neural network components.
 */
class SimpleGNN : public model_template {
public:
    /**
     * @brief Constructor for the SimpleGNN model.
     * Initializes the neural network layers (node encoder and edge classifier)
     * and registers them with the base model_template class.
     */
    SimpleGNN() {
        /**
         * @brief Initialize the node encoder module.
         * A sequential model consisting of two linear layers with a ReLU activation.
         * It transforms input node features (dimension 5) to an embedding (dimension 64).
         * - Input layer: Linear(5 -> 64)
         * - Activation: ReLU
         * - Output layer: Linear(64 -> 64)
         */
        // node_encoder = torch::nn::Sequential(...);

        /**
         * @brief Initialize the edge classifier module.
         * A sequential model that takes concatenated node embeddings of connected nodes
         * (dimension 128 = 64 + 64) and predicts edge properties (dimension 2).
         * - Input layer: Linear(128 -> 64)
         * - Activation: ReLU
         * - Output layer: Linear(64 -> 2) (e.g., for binary classification)
         */
        // edge_classifier = torch::nn::Sequential(...);

        /**
         * @brief Register the node encoder module with the base class.
         * This makes the module's parameters trackable for training and saving.
         */
        // register_module(&node_encoder);

        /**
         * @brief Register the edge classifier module with the base class.
         * This makes the module's parameters trackable for training and saving.
         */
        // register_module(&edge_classifier);
    }

    /**
     * @brief Creates a copy (clone) of the current model instance.
     * Required by the AnalysisG framework for parallel processing or other internal mechanisms.
     * @return model_template* A pointer to the newly created model instance.
     */
    model_template* clone() override {
        // return new SimpleGNN(*this);
    }

    /**
     * @brief Defines the forward pass of the GNN model.
     * This method is called during training and inference to process graph data.
     * @param data Pointer to the graph data structure containing node features, edge indices, etc.
     * @param train Boolean flag indicating whether the model is in training mode (e.g., for dropout).
     */
    void forward(graph_t* data, bool train) override {
        /**
         * @brief Retrieve node features tensor from the input graph data.
         * Assumes node features are stored under the key "features".
         */
        // torch::Tensor node_feats = *m_i_node["features"];

        /**
         * @brief Retrieve the edge index tensor from the input graph data.
         * The edge index typically has a shape of [2, num_edges], where the first row
         * contains source node indices and the second row contains destination node indices.
         */
        // torch::Tensor edge_index = data->edge_index;

        /**
         * @brief Process node features through the node encoder.
         * Generates node embeddings.
         */
        // torch::Tensor node_emb = node_encoder->forward(node_feats);

        /**
         * @brief Gather source node embeddings based on the edge index.
         */
        // torch::Tensor src = node_emb.index_select(0, edge_index[0]);

        /**
         * @brief Gather destination node embeddings based on the edge index.
         */
        // torch::Tensor dst = node_emb.index_select(0, edge_index[1]);

        /**
         * @brief Concatenate source and destination node embeddings for each edge.
         * This forms the input features for the edge classifier.
         */
        // torch::Tensor edge_input = torch::cat({src, dst}, 1);

        /**
         * @brief Process the concatenated edge features through the edge classifier.
         * Generates predictions for each edge.
         */
        // torch::Tensor edge_pred = edge_classifier->forward(edge_input);

        /**
         * @brief Register the edge predictions with the framework.
         * @param name The name to assign to this prediction output (e.g., "classification").
         * @param tensor The tensor containing the predictions.
         * This makes the predictions available for loss calculation or evaluation.
         */
        // prediction_edge_feature("classification", edge_pred);
    }

private:
    /**
     * @brief The node encoder neural network module.
     */
    // torch::nn::Sequential node_encoder{nullptr};

    /**
     * @brief The edge classifier neural network module.
     */
    // torch::nn::Sequential edge_classifier{nullptr};
};

/**
 * @brief Main entry point for the analysis script with ML training.
 * @return int Returns 0 upon successful execution, non-zero otherwise.
 */
int main() {
    /**
     * @brief Create a new analysis object.
     */
    // analysis* an = new analysis();

    /**
     * @brief Configure the output path.
     */
    // an->settings.output_path = "./output";

    /**
     * @brief Assign a run name, distinct from the previous example.
     */
    // an->settings.run_name = "quickstart_ml";

    /**
     * @brief Set the number of training epochs.
     */
    // an->settings.epochs = 5;

    /**
     * @brief Set the number of folds for k-fold cross-validation.
     */
    // an->settings.kfolds = 3;

    /**
     * @brief Set the batch size for training.
     */
    // an->settings.batch_size = 32;

    /**
     * @brief Enable training mode for the analysis.
     */
    // an->settings.training = true;

    /**
     * @brief Add input data samples.
     */
    // an->add_samples("./sample_data/", "ttbar");

    /**
     * @brief Instantiate and register the event processing template.
     */
    // ssml_mc20* event = new ssml_mc20();
    // an->add_event_template(event, "mc20");

    /**
     * @brief Instantiate and register the graph building template.
     */
    // graph_jets* graph = new graph_jets();
    // an->add_graph_template(graph, "jets");

    /**
     * @brief Instantiate the custom GNN model.
     */
    // SimpleGNN* model = new SimpleGNN();

    /**
     * @brief Define optimizer parameters.
     * Uses the Adam optimizer with a learning rate of 0.001.
     */
    // optimizer_params_t optim;
    // optim.learning_rate = 0.001;
    // optim.optimizer = "Adam";

    /**
     * @brief Add the model and its optimizer configuration to the analysis.
     * @param model Pointer to the model instance.
     * @param optim Pointer to the optimizer parameters struct.
     * @param name A unique identifier for this model ("simple_gnn").
     */
    // an->add_model(model, &optim, "simple_gnn");

    /**
     * @brief Execute the analysis pipeline, including model training.
     */
    // an->build();

    /**
     * @brief Clean up allocated resources.
     */
    // delete an; // Note: The framework typically handles deletion of added templates/models.

    /**
     * @brief Indicate successful program termination.
     */
    // return 0;
}
```

## 4. Add Physics Selections

Now let's add a physics selection to our analysis:

```cpp
/**
 * @file analysis_with_selection.cpp
 * @brief Example demonstrating AnalysisG with a physics selection step.
 *
 * This script shows how to incorporate a pre-defined physics selection
 * (topefficiency) into the analysis workflow after event processing
 * and graph building.
 */

// Include the core AnalysisG framework header.
#include <AnalysisG/analysis.h>
// Include the specific event definition for ssml_mc20 data.
#include <ssml_mc20/event.h>
// Include the specific graph building logic for jets.
#include <ssml_mc20/graphs.h>
// Include the header for the Top Efficiency physics selection.
#include <performance/topefficiency/topefficiency.h>

/**
 * @brief Main entry point for the analysis script with a physics selection.
 * @return int Returns 0 upon successful execution, non-zero otherwise.
 */
int main() {
    /**
     * @brief Create a new analysis object.
     */
    // analysis* an = new analysis();

    /**
     * @brief Configure the output path.
     */
    // an->settings.output_path = "./output";

    /**
     * @brief Assign a run name, distinct from previous examples.
     */
    // an->settings.run_name = "quickstart_selection";

    /**
     * @brief Add input data samples.
     */
    // an->add_samples("./sample_data/", "ttbar");

    /**
     * @brief Instantiate and register the event processing template.
     */
    // ssml_mc20* event = new ssml_mc20();
    // an->add_event_template(event, "mc20");

    /**
     * @brief Instantiate and register the graph building template.
     */
    // graph_jets* graph = new graph_jets();
    // an->add_graph_template(graph, "jets");

    /**
     * @brief Instantiate the Top Efficiency physics selection object.
     * This object contains logic to select events based on top quark criteria.
     */
    // topefficiency* sel = new topefficiency();

    /**
     * @brief Add the selection template to the analysis pipeline.
     * The selection will be applied after event processing and graph building.
     * @param sel Pointer to the selection object.
     * The framework uses the class name implicitly as the identifier here.
     */
    // an->add_selection_template(sel);

    /**
     * @brief Execute the analysis pipeline, including the selection step.
     */
    // an->build();

    /**
     * @brief Clean up allocated resources.
     */
    // delete an; // Note: Framework manages template deletion.

    /**
     * @brief Indicate successful program termination.
     */
    // return 0;
}
```

## 5. Accessing Results

After running your analysis, you can access the output files in the specified output directory:

```bash
# Navigate to the output directory for the selection run
cd output/quickstart_selection

# Open the output ROOT file using the ROOT interpreter
root -l selection_output.root
```

Inside ROOT, you can examine the histograms and trees generated by the selection:

```cpp
// In the ROOT interactive prompt, open a TBrowser to navigate the file contents.
TBrowser b;
```

## Next Steps

- Learn about [configuring graph features](../examples/graph_features.md)
- Explore [implementing custom models](../examples/custom_models.md)
- Read about [advanced selection techniques](../examples/advanced_selections.md)

For more detailed examples and workflows, check the [examples directory](../examples/index.md).
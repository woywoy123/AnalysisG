/**
 * @file optimizer.cxx
 * @brief Documentation for modules/optimizer/cxx/optimizer.cxx
 * 
 * This file is part of the AnalysisG framework.
 * Location: src/AnalysisG/modules/optimizer/cxx/optimizer.cxx
 */

/**
 * @defgroup modules_optimizer_cxx_optimizer_cxx optimizer.cxx
 * @brief optimizer.cxx
 * @{
 */

/**
 * @section functions Functions
 *
 * - `optimizer::optimizer(){ this -> prefix = "optimizer";`
 * - `this -> metric = new metrics();`
 * - `optimizer::~optimizer(){ delete this -> metric;`
 * - `std::map<int, model_template*>::iterator itx = this -> kfold_sessions.begin();`
 * - `for (; itx != this -> kfold_sessions.end(); ++itx){delete itx -> second;}`
 * - `void optimizer::import_dataloader(dataloader* dl){ this -> metric -> m_settings = this -> m_settings`
 * - `void optimizer::import_model_sessions(std::tuple<model_template*, optimizer_params_t*>* models){ mod`
 * - `model_template*       base = std::get<0>(*models);`
 * - `optimizer_params_t* config = std::get<1>(*models);`
 * - `base -> set_optimizer(config -> optimizer);`
 * - `base -> clone_settings(&settings);`
 * - `this -> info("_____ TESTING IMPORTED MODEL WITH OPTIMIZER PARAMS _____");`
 * - `model_template* model_k = base -> clone();`
 * - `model_k -> set_optimizer(config -> optimizer);`
 * - `model_k -> import_settings(&settings);`
 * - `model_k -> initialize(config);`
 * - `std::vector<graph_t*> rnd = this -> loader -> get_random(this -> m_settings.num_examples);`
 * - `for (size_t x(0); x < rnd.size(); ++x){`
 * - `if (x){model_k -> shush = true;}`
 * - `model_k -> check_features(rnd[x]);`
 * - `this -> success("_____ PASSED TESTS AND CONFIGURATION _____");`
 * - `void optimizer::training_loop(int k, int epoch){ std::vector<graph_t*>* smpl = this -> loader -> get`
 * - `std::vector<graph_t*>* smpl = this -> loader -> get_k_train_set(k);`
 * - `model -> evaluation_mode(false);`
 * - `model_report* mr = this -> reports[this -> m_settings.run_name + std::to_string(k)];`
 * - `if (batched){smpl = this -> loader -> build_batch(smpl, model, mr);}`
 * - `size_t l = smpl -> size();`
 * - `torch::AutoGradMode grd(true);`
 * - `for (size_t x(0); x < l; ++x){`
 * - `graph_t* gr = (*smpl)[x];`
 * - `model -> forward(gr, true);`
 * - `this -> metric -> capture(mode_enum::training, k, epoch, l);`
 * - `model -> save_state();`
 * - `std::vector<torch::optim::OptimizerParamGroup> para = model -> m_optim -> param_groups();`
 * - `for (size_t x(0); x < para.size(); ++x){mr -> current_lr.push_back(para.at(x).options().get_lr());}`
 * - `if (!batched){return;}`
 * - `this -> loader -> safe_delete(smpl);`
 * - `void optimizer::validation_loop(int k, int epoch){ model_template* model = this -> kfold_sessions[k]`
 * - `model -> evaluation_mode(true);`
 * - `std::vector<graph_t*>* smpl = this -> loader -> get_k_validation_set(k);`
 * - `model -> forward(gr, false);`
 * - `this -> metric -> capture(mode_enum::validation, k, epoch, l);`
 * - `void optimizer::evaluation_loop(int k, int epoch){ model_template* model = this -> kfold_sessions[k]`
 * - `std::vector<graph_t*>* smpl = this -> loader -> get_test_set();`
 * - `this -> metric -> capture(mode_enum::evaluation, k, epoch, l);`
 * - `void optimizer::launch_model(int k){ for (int ep(0); ep < this -> m_settings.epochs+1; ++ep){`
 * - `for (int ep(0); ep < this -> m_settings.epochs+1; ++ep){`
 * - `if (model -> epoch > ep){continue;}`
 * - `if (this -> m_settings.training){this -> training_loop(k, ep);}`
 * - `if (this -> m_settings.validation){this -> validation_loop(k, ep);}`
 * - `if (this -> m_settings.evaluation){this -> evaluation_loop(k, ep);}`
 * - `if (this -> m_settings.debug_mode){this -> metric -> dump_plots(k);}`
 * - `if (this -> m_settings.debug_mode){this -> metric -> dump_plots(k); continue;}`
 * - `while (mr -> waiting_plot){std::this_thread::sleep_for(std::chrono::microseconds(10));}`
 */

/**
 * @section variables Variables
 *
 * - `std::map<int, model_template*>::iterator itx = this -> kfold_sessions.begin();` (::private)
 * - `model_template*       base = std::get<0>(*models);` (::private)
 * - `optimizer_params_t* config = std::get<1>(*models);` (::private)
 * - `std::vector<graph_t*> rnd = this -> loader -> get_random(this -> m_settings.num_` (::private)
 * - `std::vector<graph_t*>* smpl = this -> loader -> get_k_train_set(k);` (::private)
 * - `model_report* mr = this -> reports[this -> m_settings.run_name + std::to_string(` (::private)
 * - `bool batched = this -> m_settings.batch_size > 1;` (::private)
 * - `size_t l = smpl -> size();` (::private)
 * - `std::vector<torch::optim::OptimizerParamGroup> para = model -> m_optim -> param_` (::private)
 * - `std::vector<graph_t*>* smpl = this -> loader -> get_k_validation_set(k);` (::private)
 * - `std::vector<graph_t*>* smpl = this -> loader -> get_test_set();` (::private)
 */

/** @} */
